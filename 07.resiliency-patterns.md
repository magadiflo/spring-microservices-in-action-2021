# Cuando suceden cosas malas: patrones de resiliencia con Spring Cloud y Resilience4j

Pág. 177

---

Cuando se trata de construir sistemas resilientes, la mayoría de los ingenieros de software solo tienen en cuenta la
falla total de una pieza de infraestructura o servicio crítico. Se centran en crear redundancia en cada capa de su
aplicación utilizando técnicas como la agrupación de servidores clave, el equilibrio de carga entre servicios y la
segregación de la infraestructura en múltiples ubicaciones.

Si bien estos enfoques tienen en cuenta la pérdida completa (y a menudo espectacular) de un componente del sistema,
**abordan solo una pequeña parte de la construcción de sistemas resilientes.** Cuando un servicio falla, es fácil
detectar que ya no está allí y la aplicación puede evitarlo. Sin embargo, cuando un servicio funciona con lentitud,
detectar ese rendimiento deficiente y solucionarlo es extremadamente difícil. Veamos algunas razones por las cuales:

- `La degradación del servicio puede comenzar de forma intermitente y luego cobrar impulso`. La degradación del servicio
  también puede ocurrir sólo en pequeñas ráfagas. Los primeros signos de falla pueden ser un pequeño grupo de usuarios
  quejándose de un problema hasta que, de repente, el contenedor de la aplicación agota su grupo de subprocesos y
  colapsa por completo.


- `Las llamadas a servicios remotos suelen ser sincrónicas y no interrumpen una llamada de larga duración`. El
  desarrollador de la aplicación normalmente llama a un servicio para realizar una acción y espera a que regrese el
  servicio. La persona que llama no tiene el concepto de tiempo de espera para evitar que la llamada de servicio se
  cuelgue.


- `Las aplicaciones suelen estar diseñadas para abordar fallos completos de recursos remotos, no degradaciones parciales`.
  A menudo, mientras el servicio no haya fallado por completo, una aplicación seguirá llamando a un servicio que se
  comporta mal y no fallará rápidamente. En este caso, la aplicación o el servicio que realiza la llamada puede
  degradarse sin problemas o, más probablemente, fallar debido al agotamiento de los recursos. El agotamiento de
  recursos se produce cuando un recurso limitado, como un grupo de subprocesos o una conexión de base de datos, llega al
  máximo y el cliente que llama debe esperar a que ese recurso vuelva a estar disponible.

Los patrones de resiliencia son uno de los aspectos más críticos de la arquitectura de microservicios. Este capítulo
explicará cuatro patrones de resiliencia y cómo utilizar `Spring Cloud` y `Resilience4j` para implementarlos en nuestro
servicio de licencias para que pueda fallar rápidamente cuando sea necesario.

## 7.1 ¿Qué son los patrones de resiliencia del lado del cliente?

**Los patrones de software de resiliencia del lado del cliente se centran en proteger a un cliente de un recurso
remoto** (otra llamada de microservicio o búsqueda de base de datos) contra fallas cuando el recurso remoto falla debido
a
errores o bajo rendimiento. **Estos patrones permiten que el cliente falle rápidamente y no consuma recursos valiosos,**
como conexiones de bases de datos y grupos de subprocesos. También evitan que el problema del mal rendimiento del
servicio remoto se propague `"ascendente"` a los consumidores del cliente. En este capítulo, veremos cuatro patrones de
resiliencia del cliente. La `Figura 7.1` demuestra cómo estos patrones se ubican entre el consumidor del servicio de
microservicio y el microservicio.

![36.four-client-resiliency-patterns.png](./assets/36.four-client-resiliency-patterns.png)

**Estos patrones (client-side load balancing, circuit breaker, fallback, and bulkhead) `se implementan en el cliente`
(microservicio) que llama al recurso remoto. La implementación de estos patrones se ubica lógicamente entre el cliente
que consume los recursos remotos y el recurso mismo.** Dediquemos un tiempo a cada uno de estos patrones.

## Client-side load balancing (Equilibrio de carga del lado del cliente)

Presentamos el patrón `client-side load balancing` en el capítulo 6 cuando hablamos sobre el
descubrimiento de servicios. El equilibrio de carga del lado del cliente implica que el cliente busque todas las
instancias individuales de un servicio desde un agente de descubrimiento de servicios (como Netflix Eureka) y luego
almacene en caché la ubicación física de dichas instancias de servicio.

Cuando un consumidor de servicios necesita llamar a una instancia de servicio, el `client-side load balancing`
devuelve una ubicación del conjunto de ubicaciones de servicios que mantiene. Debido a que el balanceador de
carga del lado del cliente se encuentra entre el cliente del servicio y el consumidor del servicio, el balanceador de
carga puede detectar si una instancia de servicio arroja errores o se comporta mal. Si el `client-side load balancing`
**detecta un problema, puede eliminar esa instancia de servicio del grupo de ubicaciones de servicio
disponibles y evitar que futuras llamadas lleguen a esa instancia de servicio.**

Este es precisamente el comportamiento que las bibliotecas `Spring Cloud Load Balancer` proporcionan de forma
inmediata (sin configuración adicional). Debido a que ya cubrimos el `client-side load balancing` con
`Spring Cloud Load Balancer` en el capítulo 6, no entraremos en más detalles sobre eso en este capítulo.

## Circuit breaker (Interruptor automático)

El patrón `circuit breaker` sigue el modelo de interrupción automática eléctrica. En un sistema eléctrico, un circuit
breaker detecta si fluye demasiada corriente a través del cable. Si el circuit breaker detecta un problema, corta la
conexión con el resto del sistema eléctrico y evita que el sistema fríe los componentes posteriores.

Con un `circuit breaker` de software, cuando se llama a un servicio remoto, el circuit breaker monitorea la llamada. Si
las llamadas tardan demasiado, el circuit breaker interviene y corta la llamada. El patrón circuit breaker también
monitorea todas las llamadas a un recurso remoto, y si fallan suficientes llamadas, la implementación del circuit
breaker `saltará`, fallando rápidamente y previniendo futuras llamadas al recurso remoto que está fallando.

## Fallback processing (Procesamiento alternativo)

Con el patrón `fallback`, cuando falla una llamada de servicio remoto, en lugar de generar una excepción, el consumidor
del servicio ejecuta una ruta de código alternativa e intenta llevar a cabo la acción por otros medios. Por lo general,
esto implica buscar datos de otra fuente de datos o poner en cola la solicitud del usuario para su procesamiento futuro.
La llamada del usuario no se muestra como una excepción que indica un problema, pero se le puede notificar que su
solicitud deberá intentarse más adelante.

Por ejemplo, supongamos que tiene un sitio de comercio electrónico que monitorea el comportamiento de sus usuarios y les
brinda recomendaciones sobre otros artículos que podrían querer comprar. Normalmente, llamaría a un microservicio para
ejecutar un análisis del comportamiento anterior del usuario y devolver una lista de recomendaciones adaptadas a ese
usuario específico. Sin embargo, si el servicio de preferencias falla, su alternativa podría ser recuperar una lista más
general de preferencias que se base en todas las compras de los usuarios, que es mucho más generalizada. Y estos datos
pueden provenir de un servicio y una fuente de datos completamente diferentes.

## Bulkheads (Mamparos)

El patrón `bulkheads` se basa en un concepto de la construcción de barcos. Un barco está dividido en compartimentos
llamados `mamparos`, que están totalmente segregados y estancos. Incluso si el casco del barco se perfora, un mamparo
mantiene el agua confinada al área del barco donde ocurrió el pinchazo y evita que todo el barco se llene de agua y se
hunda.

El mismo concepto se puede aplicar a un servicio que debe interactuar con múltiples recursos remotos. Cuando se utiliza
el patrón `bulkheads`, se dividen las llamadas a recursos remotos en sus propios grupos de subprocesos y se reduce el
riesgo de que un problema con una llamada lenta a un recurso remoto destruya toda la aplicación.

Los grupos de subprocesos actúan como `mamparos` para su servicio. Cada recurso remoto está segregado y asignado a un
grupo de subprocesos. Si un servicio responde lentamente, el grupo de subprocesos para ese tipo de llamada de servicio
puede saturarse y dejar de procesar solicitudes. Asignar servicios a grupos de subprocesos ayuda a evitar este tipo de
cuello de botella para que otros servicios no se saturen.

