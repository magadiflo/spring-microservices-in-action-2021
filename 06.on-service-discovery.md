# Sobre el service discovery

Pág. 148

---

En cualquier arquitectura distribuida, necesitamos encontrar el nombre de host o la dirección IP donde se encuentra una
máquina. Este concepto ha existido desde el comienzo de la informática distribuida y se conoce formalmente
como `"service discovery"`. El service discovery puede ser algo tan simple como mantener un archivo de
propiedades con las direcciones de todos los servicios remotos utilizados por una aplicación, o algo tan formalizado
como un repositorio `Universal Description, Discovery and Integration (UDDI)`. El service discovery es
fundamental para las aplicaciones de microservicios basadas en la nube por dos razones clave:

- `Escalamiento horizontal o  scale out`: este patrón generalmente requiere ajustes en la arquitectura de la aplicación,
  como agregar más instancias de un servicio dentro de un servicio en la nube y más contenedores.


- `Resiliencia`: este patrón se refiere a la capacidad de absorber el impacto de los problemas dentro de una
  arquitectura o servicio sin afectar el negocio. Las arquitecturas de microservicios deben ser extremadamente sensibles
  para evitar que un problema en un solo servicio (o instancia de servicio) se propague en cascada hacia los
  consumidores del servicio.

En primer lugar, **el service discovery permite al equipo de aplicaciones escalar rápidamente
(horizontalmente) la cantidad de instancias de servicios que se ejecutan en un entorno.** Los consumidores del servicio
se abstraen de la ubicación física del servicio. Debido a que los consumidores del servicio no conocen la ubicación
física de las instancias de servicio reales, se pueden agregar o eliminar nuevas instancias de servicio del conjunto de
servicios disponibles.

Esta capacidad para escalar servicios rápidamente sin interrumpir a los consumidores del servicio es un concepto
atractivo. Puede ayudar a un equipo de desarrollo, acostumbrado a construir una aplicación monolítica para un solo
cliente (por ejemplo, para un único cliente), a dejar de pensar en escalar solo en términos de agregar hardware más
grande y mejor `(escalamiento vertical)`, y en su lugar, adoptar el enfoque más robusto de escalar agregando más
servidores con más servicios `(escalamiento horizontal)`.

Un enfoque monolítico suele llevar a los equipos de desarrollo a comprar en exceso sus necesidades de capacidad. Los
aumentos de capacidad se producen en grupos y picos y rara vez son un proceso fluido y constante. Por ejemplo, considere
el número incremental de request realizadas a sitios de comercio electrónico antes de algunos días festivos. Los
microservicios nos permiten escalar nuevas instancias de servicios bajo demanda. El service discovery ayuda a
abstraer estas implementaciones para que ocurran lejos del consumidor del servicio.

El segundo beneficio del service discovery es que ayuda a aumentar la resiliencia de la aplicación. Cuando una
instancia de un microservicio se vuelve inestable o no está disponible, la mayoría de los motores de descubrimiento de
servicios eliminan esa instancia de su lista interna de servicios disponibles. El daño causado por un servicio caído se
minimiza porque el motor de service discovery redirige los servicios evitando el servicio no disponible.

Veamos ahora cómo puede implementar un mecanismo sólido de service discovery para sus aplicaciones basadas en
la nube.

## Service discovery en la nube

La solución para un entorno de microservicios basado en la nube es utilizar un mecanismo de service discovery
que sea:

- `Altamente disponible`: el service discovery debe ser capaz de admitir un entorno de agrupación en
  clústeres "caliente" donde las búsquedas de servicios se puedan compartir entre varios nodos en un clúster de
  service discovery. Si un nodo deja de estar disponible, otros nodos del clúster deberían poder hacerse
  cargo.<br><br>
  **Un clúster se puede definir como un grupo de múltiples instancias de servidor.** Todas las instancias de este
  entorno tienen una configuración idéntica y trabajan juntas para ofrecer alta disponibilidad, confiabilidad y
  escalabilidad. Un clúster, combinado con un load balancer, puede ofrecer conmutación por error para prevenir
  interrupciones del servicio y replicación de sesiones para almacenar datos de sesión.


- `Peet-to-peer`: cada nodo en el clúster de service discovery comparte el estado de una instancia de
  servicio.


- `Load balancer`, el service discovery necesita equilibrar dinámicamente la carga de las solicitudes en todas
  las instancias de servicio. Esto garantiza que las invocaciones de servicio se distribuyan entre todas las instancias
  de servicio gestionadas por él. En muchos sentidos, el service discovery reemplaza a los balanceadores de
  carga más estáticos y administrados manualmente que se encuentran en muchas de las primeras implementaciones de
  aplicaciones web.


- `Resilient`, el cliente del service discovery debe almacenar en caché local la información del servicio.
  El almacenamiento en caché local permite la degradación gradual de la función de descubrimiento de
  servicios, de modo que si el servicio discovery service deja de estar disponible, las aplicaciones aún
  pueden funcionar y localizar los servicios en función de la información mantenida en su caché local.


- `Fault tolerant`, el service discovery debe detectar cuándo una instancia de servicio no está en buen estado
  y eliminar esa instancia de la lista de servicios disponibles que pueden aceptar solicitudes de clientes. Debe
  detectar estas fallas en los servicios y tomar medidas sin intervención humana.

En las siguientes secciones, vamos a

- Explicar la arquitectura conceptual de cómo funciona un agente de service discovery basado en la nube.
- Mostrarle cómo el almacenamiento en caché y el load balancing del lado del cliente permiten que el servicio
  continúe funcionando incluso cuando el agente service discovery no está disponible.
- Mostrarle cómo implementar el service discovery utilizando Spring Cloud y los agentes de descubrimiento de
  servicios Eureka de Netflix.

## La arquitectura del Service Discovery

Para comenzar nuestra discusión sobre el service discovery, debemos comprender cuatro conceptos. Estos
conceptos generales suelen compartirse en todas las implementaciones de service discovery:

- `Registro de servicio`: cómo se registra un servicio con el agente de service discovery.
- `Búsqueda de dirección de servicio por parte del cliente`: cómo un cliente de servicio busca información de servicio
- `Intercambio de información`: cómo los nodos comparten información de servicio.
- `Supervisión del estado`: cómo los servicios comunican su estado al agente de service discovery.

El objetivo principal del service discovery es tener una arquitectura donde nuestros servicios indiquen dónde
están ubicados físicamente en lugar de tener que configurar manualmente su ubicación. La `Figura 6.2` muestra cómo se
agregan y eliminan instancias de servicio, y cómo actualizan el agente de service discovery y quedan
disponibles para procesar las solicitudes de los usuarios. La `Figura 6.2` muestra el flujo de los cuatro puntos
anteriores (registro de servicios, búsqueda de service discovery, intercambio de información y monitoreo del
estado) y lo que normalmente ocurre cuando implementamos un patrón de service discovery. En la figura, se han
iniciado uno o más nodos de service discovery. Estas instancias de service discovery generalmente no
tienen un equilibrador de carga frente a ellas.

![31.service-instances-added.png](./assets/31.service-instances-added.png)

A medida que se inician las instancias de servicio, `registrarán su ubicación física, ruta y puerto` que una o más
instancias de service discovery pueden usar para acceder a las instancias. Si bien cada instancia de un
servicio tiene una dirección IP y un puerto únicos, cada instancia de servicio que aparece se registra con el mismo ID
de servicio. **Un `ID de servicio` no es más que una clave que identifica de forma única un grupo de las mismas
instancias de servicio.**

Por lo general, un servicio solo se registra en una instancia de servicio de service discovery. La mayoría de
las implementaciones de service discovery utilizan un modelo de propagación de datos de igual a igual, donde
los datos de cada instancia de servicio se comunican a todos los demás nodos del clúster. Dependiendo de la
implementación del service discovery, el mecanismo de propagación puede usar una lista codificada de servicios
para propagar o usar un protocolo de multidifusión como el protocolo de estilo de chismes o infección para permitir que
otros nodos "descubran" cambios en el clúster.

Finalmente, cada instancia de servicio ingresa o retira su estado mediante el servicio de service discovery.
Cualquier servicio que no devuelva una buena verificación de estado se elimina del grupo de instancias de servicio
disponibles. Una vez que un servicio se registra en un servicio de service discovery, está listo para ser
utilizado por una aplicación o servicio que necesita hacer uso de sus capacidades. Existen diferentes modelos para que
un cliente descubra un servicio.

Como primer enfoque, el cliente confía únicamente en el motor de descubrimiento de servicios para resolver las
ubicaciones de los servicios cada vez que se llama a un servicio. Con este enfoque, el motor de descubrimiento de
servicios se invoca cada vez que se realiza una llamada a una instancia de microservicio registrada. Desafortunadamente,
este enfoque es frágil porque el cliente del servicio depende completamente del motor de descubrimiento de servicios
para encontrar e invocar un servicio.

Un enfoque más sólido utiliza lo que se llama `load balancing del lado del cliente`. Este mecanismo utiliza un
algoritmo como `zone-specific` o `round-robin` para invocar las instancias de los servicios de llamada. Cuando decimos
**"load balancing con algoritmo round-robin"**, nos referimos a una forma de distribuir las solicitudes de los clientes
entre varios servidores. Consiste en reenviar una solicitud de cliente a cada uno de los servidores por turno. Una
ventaja de utilizar el `load balancing lado del cliente con Eureka` es que cuando una instancia de servicio
deja de funcionar, se elimina del registro. Una vez hecho esto, el `load balancing del lado del cliente` se
actualiza sin intervención manual estableciendo una comunicación constante con el servicio de registro. La `figura 6.3`
ilustra este enfoque.

![32.client-side-load-balancing.png](./assets/32.client-side-load-balancing.png)

En este modelo, cuando un cliente consumidor necesita invocar un servicio

1. Se comunica con el service discovery para todas las instancias que solicita un consumidor de servicios
   (cliente) y luego almacena en caché los datos localmente en la máquina del consumidor de servicios.


2. Cada vez que un cliente quiere llamar al servicio, el consumidor del servicio busca la información de ubicación del
   servicio en la `memoria caché`. Por lo general, **el almacenamiento en caché del lado del cliente utilizará un
   simple algoritmo de equilibrio de carga, como el algoritmo load-balancing round-robin**, para garantizar que las
   llamadas de servicio se distribuyan entre múltiples instancias de servicio.


3. Luego, el cliente se comunica periódicamente con el service discovery y actualiza su caché de instancias de
   servicio. La caché del cliente eventualmente es consistente, pero siempre existe el riesgo de que cuando el cliente
   contacta la instancia de descubrimiento de servicios para una actualización y se realizan llamadas, las llamadas se
   dirijan a una instancia de servicio que no está en buen estado.

Si durante el curso de la llamada a un servicio, la llamada al servicio falla, la caché de descubrimiento de servicios
local se invalida y el cliente de descubrimiento de servicios intentará actualizar sus entradas desde el agente de
descubrimiento de servicios. Tomemos ahora el patrón de descubrimiento de servicios genérico y apliquémoslo a nuestro
dominio del problema O-stock.

## Service discovery en acción usando Spring y Netflix Eureka

En esta sección, implementaremos el descubrimiento de servicios configurando un agente de descubrimiento de servicios y
luego registraremos dos servicios con el agente. Con esta implementación, usaremos la información recuperada por el
descubrimiento de servicios para llamar a un servicio desde otro servicio. `Spring Cloud` ofrece múltiples métodos para
buscar información de un agente de descubrimiento de servicios. Analizaremos las fortalezas y debilidades de cada
enfoque.

Nuevamente, `Spring Cloud` hace que este tipo de configuración sea trivial. Usaremos `Spring Cloud` y el
motor `Eureka Service Discovery de Netflix` para implementar su patrón de descubrimiento de servicios. Para el *
*equilibrio de carga del lado del cliente**, usaremos `Spring Cloud Load Balancer`.

**NOTA**
> En este capítulo, no usaremos `Ribbon`. `Ribbon` era el equilibrador de carga del lado del cliente de facto para
> comunicaciones basadas en REST entre aplicaciones que utilizan Spring Cloud. Aunque el equilibrio de carga del lado
> del cliente de Netflix Ribbon era una solución estable, ahora ha entrado en modo de mantenimiento, por lo que,
> lamentablemente, ya no se desarrollará más.

En esta sección, explicaremos cómo utilizar Spring Cloud Load Balancer, que reemplaza a Ribbon. Actualmente, Spring
Cloud Load Balancer todavía está en desarrollo activo, por lo que se esperan nuevas funcionalidades pronto. En los dos
capítulos anteriores, mantuvimos nuestro servicio de licencias simple e incluimos el nombre de la organización para las
licencias con los datos de la licencia. En este capítulo, dividiremos la información de la organización en su propio
servicio. **La `Figura 6.4` muestra la implementación del almacenamiento en caché del lado del cliente con Eureka para
nuestros microservicios O-stock.**

Cuando se invoca el servicio de licencias, llamará al servicio de la organización para recuperar la información de la
organización asociada con el ID de la organización designada.

![33.client-and-eureka.png](./assets/33.client-and-eureka.png)

La resolución real de la ubicación del servicio de la organización se mantiene en un registro de descubrimiento de
servicios. Para este ejemplo, registraremos dos instancias del servicio de la organización con un registro de
descubrimiento de servicios y luego usaremos el equilibrio de carga del lado del cliente para buscar y almacenar en
caché el registro en cada instancia de servicio. La `figura 6.4` muestra esta disposición:

1. A medida que los servicios se inician, los servicios de organización y licencia se registran en el servicio Eureka.
   Este proceso de registro le dice a Eureka la ubicación física y el número de puerto de cada instancia de servicio,
   junto con un ID de servicio para el servicio que se está iniciando.
2. Cuando el servicio de licencias llama al servicio de la organización, utiliza `Spring Cloud Load Balancer` para
   proporcionar equilibrio de carga del lado del cliente. `Load Balancer` se pone en contacto con el `servicio Eureka`
   para recuperar información de ubicación del servicio y luego la almacena en caché localmente.
3. Periódicamente, `Spring Cloud Load Balancer` hará ping al servicio `Eureka` y actualizará su caché local de
   ubicaciones de servicios.

Cualquier nueva instancia de servicio de la organización ahora es visible para el servicio de licencias localmente,
mientras que las instancias en mal estado se eliminan de la caché local. Implementaremos este diseño configurando
nuestro servicio `Spring Cloud Eureka`.

