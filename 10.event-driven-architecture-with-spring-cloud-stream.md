# Event-driven architecture with Spring Cloud Stream

Pág. 275

---

Este capítulo trata sobre cómo diseñar e implementar nuestros microservicios basados en Spring para comunicarse con
otros microservicios mediante mensajes asincrónicos. El uso de mensajes asincrónicos para comunicarse entre aplicaciones
no es nuevo. Lo nuevo es el concepto de utilizar mensajes para comunicar eventos que representan cambios de estado. Este
concepto se llama `arquitectura basada en eventos (EDA)`. También se conoce
como `arquitectura basada en mensajes (MDA).` Lo que nos permite hacer un enfoque basado en EDA es construir sistemas
altamente desacoplados que puedan reaccionar a los cambios sin estar estrechamente acoplados a bibliotecas o servicios
específicos. Cuando se combina con microservicios, EDA nos permite agregar rápidamente nuevas funciones a nuestra
aplicación simplemente haciendo que el servicio escuche el flujo de eventos (mensajes) que emite nuestra aplicación.

El proyecto Spring Cloud hace que sea trivial crear soluciones basadas en mensajes a través del subproyecto
`Spring Cloud Stream`. `Spring Cloud Stream` nos permite implementar fácilmente la publicación y el consumo de mensajes
mientras protegemos nuestros servicios de los detalles de implementación asociados con la plataforma de mensajería
subyacente.

## 10.1 El caso de la mensajería, EDA y los microservicios

Para implementar una solución en caché, necesitamos considerar los siguientes tres requisitos básicos:

1. `Los datos almacenados en caché deben ser coherentes en todas las instancias del servicio de licencias`. Esto
   significa que no podemos almacenar en caché los datos localmente dentro del servicio de licencia porque queremos
   garantizar que se lean los mismos datos de la organización independientemente de la instancia de servicio que los
   reciba.


2. `No podemos almacenar en caché los datos de la organización en la memoria del contenedor que aloja el servicio de licencias`.
   El contenedor de tiempo de ejecución que aloja nuestro servicio suele tener un tamaño restringido y puede obtener
   datos utilizando diferentes patrones de acceso. Un caché local puede introducir complejidad porque tenemos que
   garantizar que nuestro caché local esté sincronizado con todos los demás servicios del clúster.


3. `Cuando el registro de una organización cambia mediante una actualización o eliminación, queremos que el servicio de licencias reconozca que ha habido un cambio de estado en el servicio de la organización`.
   Luego, el servicio de licencias debería invalidar cualquier dato almacenado en caché que tenga para esa organización
   específica y expulsarlo del caché.

Veamos dos enfoques para implementar estos requisitos. `El primer enfoque` implementará los requisitos establecidos
anteriormente utilizando un modelo de solicitud-respuesta sincrónica. Cuando el estado de la organización cambia, los
servicios de organización y licencias se comunicarán entre sí a través de sus puntos finales REST.

Para `el segundo enfoque`, el servicio de la organización emitirá un evento asincrónico (mensaje) para comunicar que
los datos de su organización han cambiado. Luego, el servicio de la organización publicará un mensaje en una cola, que
indicará que un registro de la organización se actualizó o eliminó: un cambio de estado. El servicio de licencias
escuchará a un intermediario (agente de mensajes o cola) para determinar si ocurrió un evento de la organización y, de
ser así, borrará los datos de la organización de su caché.

## Uso del enfoque request-response síncrono para comunicar cambios de estado

Para la caché de datos de nuestra organización, usaremos `Redis` (https://redis.io/), un almacén de `key-value`
distribuido que se utiliza como `base de datos, caché o message broker`. La `Figura 10.1` proporciona una
descripción general de alto nivel de cómo construir una solución de `almacenamiento en caché` utilizando un modelo de
programación de `request-response síncrono` tradicional como `Redis`.

![01.synchronous-request-response.png](assets/chapter-10/01.synchronous-request-response.png)

En la `figura 10.1`, cuando un usuario llama al servicio de licencias, el servicio de licencias deberá buscar los datos
de la organización. Para hacerlo, el servicio de licencias primero recuperará la organización deseada por su ID de un
clúster de Redis. Si el servicio de licencias no puede encontrar los datos de la organización, llamará al servicio de la
organización utilizando un punto final basado en REST, almacenando los datos devueltos en Redis antes de devolver los
datos de la organización al usuario.

Si alguien actualiza o elimina el registro de la organización utilizando el punto final REST del servicio de la
organización, el servicio de la organización deberá llamar a un punto final expuesto en el servicio de licencias y
decirle que invalide los datos de la organización en su caché. En la `figura 10.1`, si observamos dónde el servicio de
la organización vuelve a llamar al servicio de licencias para indicarle que invalide el caché de Redis, podemos ver al
menos tres problemas:

- Los servicios de organización y de licencias están estrechamente vinculados. Este acoplamiento introduce fragilidad
  entre los servicios.
- Si el punto final del servicio de licencias para invalidar la caché cambia, el servicio de la organización tiene que
  cambiar. Este enfoque es inflexible.
- No podemos agregar nuevos consumidores de los datos de la organización sin modificar el código en el servicio de la
  organización para verificar que llame al servicio de licencias para informarle sobre cualquier cambio.

### Acoplamiento estrecho entre servicios

Para recuperar datos, el servicio de licencia depende del servicio de la organización. Sin embargo, al hacer que el
servicio de la organización se comunique directamente con el servicio de licencias cuando se actualiza o elimina un
registro de la organización, hemos introducido el acoplamiento del servicio de la organización al servicio de
licencias (`figura 10.1`). Para que los datos en el caché de Redis se invaliden, el servicio de la organización
necesita un punto final expuesto en el servicio de licencias al que se pueda llamar para invalidar su caché de Redis, o
el servicio de la organización necesita comunicarse directamente con el servidor de Redis propiedad del servicio de
licencias. para borrar los datos que contiene.

Hacer que el servicio de la organización se comunique con Redis tiene sus propios problemas porque estamos hablando con
un almacén de datos que pertenece directamente a otro servicio. En un entorno de microservicios, esto es un gran no-no.
Si bien se puede argumentar que los datos de la organización pertenecen legítimamente al servicio de la organización, el
servicio de licencia los utiliza en un contexto específico y potencialmente podría transformar los datos o crear reglas
comerciales en torno a ellos. Si el servicio de la organización habla directamente con el servicio Redis,
accidentalmente puede infringir las reglas implementadas por el equipo propietario del servicio de licencias.

### Fragilidad entre los servicios

El estrecho vínculo entre el servicio de licencias y el servicio de organización también introdujo fragilidad entre los
dos servicios. Si el servicio de licencias no funciona o funciona con lentitud, el servicio de la organización puede
verse afectado ya que el servicio de la organización ahora se comunica directamente con el servicio de licencias.
Nuevamente, si el servicio de la organización se comunica directamente con el almacén de datos de Redis del servicio de
licencias, creamos una dependencia entre el servicio de la organización y Redis. En este escenario, cualquier problema
con el servidor Redis compartido ahora tiene el potencial de desactivar ambos servicios.

### Inflexibilidad para sumar nuevos consumidores a los cambios en el servicio de la organización

Con el modelo de la `figura 10.1`, si tuviéramos otro servicio interesado en los cambios de datos de la organización,
necesitaríamos agregar otra llamada del servicio de la organización al otro servicio. Esto significa un cambio de código
y una nueva implementación del servicio de la organización, lo que puede introducir un estado de inflexibilidad en
nuestro código.

Si utilizamos el modelo sincrónico de solicitud-respuesta para comunicar el cambio de estado, comenzamos a ver un patrón
de dependencia similar a una web entre nuestros servicios principales en nuestra aplicación y otros servicios. Los
centros de estas webs se convierten en nuestros principales puntos de fallo dentro de nuestra aplicación.