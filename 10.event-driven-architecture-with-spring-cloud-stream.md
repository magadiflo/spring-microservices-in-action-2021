# Event-driven architecture with Spring Cloud Stream

Pág. 275

---

Este capítulo trata sobre cómo diseñar e implementar nuestros microservicios basados en Spring para comunicarse con
otros microservicios mediante mensajes asincrónicos. El uso de mensajes asincrónicos para comunicarse entre aplicaciones
no es nuevo. Lo nuevo es el concepto de utilizar mensajes para comunicar eventos que representan cambios de estado. Este
concepto se llama `arquitectura basada en eventos (EDA)`. También se conoce
como `arquitectura basada en mensajes (MDA).` Lo que nos permite hacer un enfoque basado en EDA es construir sistemas
altamente desacoplados que puedan reaccionar a los cambios sin estar estrechamente acoplados a bibliotecas o servicios
específicos. Cuando se combina con microservicios, EDA nos permite agregar rápidamente nuevas funciones a nuestra
aplicación simplemente haciendo que el servicio escuche el flujo de eventos (mensajes) que emite nuestra aplicación.

El proyecto Spring Cloud hace que sea trivial crear soluciones basadas en mensajes a través del subproyecto
`Spring Cloud Stream`. `Spring Cloud Stream` nos permite implementar fácilmente la publicación y el consumo de mensajes
mientras protegemos nuestros servicios de los detalles de implementación asociados con la plataforma de mensajería
subyacente.

## 10.1 El caso de la mensajería, EDA y los microservicios

Para implementar una solución en caché, necesitamos considerar los siguientes tres requisitos básicos:

1. `Los datos almacenados en caché deben ser coherentes en todas las instancias del servicio de licencias`. Esto
   significa que no podemos almacenar en caché los datos localmente dentro del servicio de licencia porque queremos
   garantizar que se lean los mismos datos de la organización independientemente de la instancia de servicio que los
   reciba.


2. `No podemos almacenar en caché los datos de la organización en la memoria del contenedor que aloja el servicio de licencias`.
   El contenedor de tiempo de ejecución que aloja nuestro servicio suele tener un tamaño restringido y puede obtener
   datos utilizando diferentes patrones de acceso. Un caché local puede introducir complejidad porque tenemos que
   garantizar que nuestro caché local esté sincronizado con todos los demás servicios del clúster.


3. `Cuando el registro de una organización cambia mediante una actualización o eliminación, queremos que el servicio de licencias reconozca que ha habido un cambio de estado en el servicio de la organización`.
   Luego, el servicio de licencias debería invalidar cualquier dato almacenado en caché que tenga para esa organización
   específica y expulsarlo del caché.

Veamos dos enfoques para implementar estos requisitos. `El primer enfoque` implementará los requisitos establecidos
anteriormente utilizando un modelo de solicitud-respuesta sincrónica. Cuando el estado de la organización cambia, los
servicios de organización y licencias se comunicarán entre sí a través de sus puntos finales REST.

Para `el segundo enfoque`, el servicio de la organización emitirá un evento asincrónico (mensaje) para comunicar que
los datos de su organización han cambiado. Luego, el servicio de la organización publicará un mensaje en una cola, que
indicará que un registro de la organización se actualizó o eliminó: un cambio de estado. El servicio de licencias
escuchará a un intermediario (agente de mensajes o cola) para determinar si ocurrió un evento de la organización y, de
ser así, borrará los datos de la organización de su caché.

## Uso del enfoque request-response síncrono para comunicar cambios de estado

Para la caché de datos de nuestra organización, usaremos `Redis` (https://redis.io/), un almacén de `key-value`
distribuido que se utiliza como `base de datos, caché o message broker`. La `Figura 10.1` proporciona una
descripción general de alto nivel de cómo construir una solución de `almacenamiento en caché` utilizando un modelo de
programación de `request-response síncrono` tradicional como `Redis`.

![01.synchronous-request-response.png](assets/chapter-10/01.synchronous-request-response.png)

En la `figura 10.1`, cuando un usuario llama al servicio de licencias, el servicio de licencias deberá buscar los datos
de la organización. Para hacerlo, el servicio de licencias primero recuperará la organización deseada por su ID de un
clúster de Redis. Si el servicio de licencias no puede encontrar los datos de la organización, llamará al servicio de la
organización utilizando un punto final basado en REST, almacenando los datos devueltos en Redis antes de devolver los
datos de la organización al usuario.

Si alguien actualiza o elimina el registro de la organización utilizando el punto final REST del servicio de la
organización, el servicio de la organización deberá llamar a un punto final expuesto en el servicio de licencias y
decirle que invalide los datos de la organización en su caché. En la `figura 10.1`, si observamos dónde el servicio de
la organización vuelve a llamar al servicio de licencias para indicarle que invalide el caché de Redis, podemos ver al
menos tres problemas:

- Los servicios de organización y de licencias están estrechamente vinculados. Este acoplamiento introduce fragilidad
  entre los servicios.
- Si el punto final del servicio de licencias para invalidar la caché cambia, el servicio de la organización tiene que
  cambiar. Este enfoque es inflexible.
- No podemos agregar nuevos consumidores de los datos de la organización sin modificar el código en el servicio de la
  organización para verificar que llame al servicio de licencias para informarle sobre cualquier cambio.

### Acoplamiento estrecho entre servicios

Para recuperar datos, el servicio de licencia depende del servicio de la organización. Sin embargo, al hacer que el
servicio de la organización se comunique directamente con el servicio de licencias cuando se actualiza o elimina un
registro de la organización, hemos introducido el acoplamiento del servicio de la organización al servicio de
licencias (`figura 10.1`). Para que los datos en el caché de Redis se invaliden, el servicio de la organización
necesita un punto final expuesto en el servicio de licencias al que se pueda llamar para invalidar su caché de Redis, o
el servicio de la organización necesita comunicarse directamente con el servidor de Redis propiedad del servicio de
licencias. para borrar los datos que contiene.

Hacer que el servicio de la organización se comunique con Redis tiene sus propios problemas porque estamos hablando con
un almacén de datos que pertenece directamente a otro servicio. En un entorno de microservicios, esto es un gran no-no.
Si bien se puede argumentar que los datos de la organización pertenecen legítimamente al servicio de la organización, el
servicio de licencia los utiliza en un contexto específico y potencialmente podría transformar los datos o crear reglas
comerciales en torno a ellos. Si el servicio de la organización habla directamente con el servicio Redis,
accidentalmente puede infringir las reglas implementadas por el equipo propietario del servicio de licencias.

### Fragilidad entre los servicios

El estrecho vínculo entre el servicio de licencias y el servicio de organización también introdujo fragilidad entre los
dos servicios. Si el servicio de licencias no funciona o funciona con lentitud, el servicio de la organización puede
verse afectado ya que el servicio de la organización ahora se comunica directamente con el servicio de licencias.
Nuevamente, si el servicio de la organización se comunica directamente con el almacén de datos de Redis del servicio de
licencias, creamos una dependencia entre el servicio de la organización y Redis. En este escenario, cualquier problema
con el servidor Redis compartido ahora tiene el potencial de desactivar ambos servicios.

### Inflexibilidad para sumar nuevos consumidores a los cambios en el servicio de la organización

Con el modelo de la `figura 10.1`, si tuviéramos otro servicio interesado en los cambios de datos de la organización,
necesitaríamos agregar otra llamada del servicio de la organización al otro servicio. Esto significa un cambio de código
y una nueva implementación del servicio de la organización, lo que puede introducir un estado de inflexibilidad en
nuestro código.

Si utilizamos el modelo sincrónico de solicitud-respuesta para comunicar el cambio de estado, comenzamos a ver un patrón
de dependencia similar a una web entre nuestros servicios principales en nuestra aplicación y otros servicios. Los
centros de estas webs se convierten en nuestros principales puntos de fallo dentro de nuestra aplicación.

## Uso de mensajería para comunicar cambios de estado entre servicios

Vamos a inyectar un `topic` entre el servicio de licencias y organización con un enfoque de mensajería. El sistema de
mensajería no se utilizará para leer datos del servicio de la organización, sino que el servicio de la organización lo
utilizará para publicar cualquier cambio de estado dentro de los datos administrados por el servicio de la organización
cuando estos ocurran. La `figura 10.2` demuestra este enfoque.

![02.messages-queue.png](assets/chapter-10/02.messages-queue.png)

En el modelo de la `figura 10.2`, cuando los datos de la organización cambian, el servicio de la organización publica un
mensaje en un topic. El servicio de licencias monitorea el topic en busca de mensajes y, cuando llega un mensaje, borra
el registro de la organización correspondiente de la caché de Redis. Cuando se trata del estado de comunicación, la cola
de mensajes actúa como intermediaria entre los servicios de licencia y organización. Este enfoque ofrece cuatro
beneficios: acoplamiento flexible, durabilidad, escalabilidad y flexibilidad.

### Bajo acoplamiento

Una aplicación de microservicios puede estar compuesta por docenas de servicios pequeños y distribuidos que interactúan
entre sí y con los datos administrados entre sí. Como vimos con el diseño síncrono propuesto anteriormente, una
respuesta HTTP síncrona crea una fuerte dependencia entre los servicios de licencia y de organización. No podemos
eliminar estas dependencias por completo, pero podemos intentar minimizarlas exponiendo solo los puntos finales que
administran directamente los datos propiedad del servicio.

Un enfoque de mensajería nos permite desacoplar los dos servicios porque, cuando se trata de comunicar cambios de
estado, ninguno de los servicios conoce al otro. Cuando el servicio de la organización necesita publicar un cambio de
estado, escribe un mensaje en una cola. El servicio de licencias sólo sabe que recibe un mensaje; no tiene idea quien ha
publicado el mensaje.

### Durabilidad

La presencia de la cola nos permite garantizar que se entregará un mensaje incluso si el consumidor del servicio está
caído. Por ejemplo, el servicio de la organización puede seguir publicando mensajes incluso si el servicio de licencia
no está disponible. Los mensajes se almacenan en la cola y permanecen allí hasta que el servicio de licencia esté
disponible. Por el contrario, con la combinación de caché y cola, si el servicio de la organización no funciona, el
servicio de licencias puede degradarse sin problemas porque al menos parte de los datos de la organización estarán en su
caché. A veces, los datos antiguos son mejores que ningún dato.

### Escalabilidad

Debido a que los mensajes se almacenan en una cola, el remitente del mensaje no tiene que esperar una respuesta del
consumidor del mensaje. El remitente puede seguir su camino y seguir trabajando. Del mismo modo, si un consumidor que
lee un mensaje de la cola no procesa los mensajes lo suficientemente rápido, es una tarea trivial atraer a más
consumidores y hacer que procesen los mensajes. Este enfoque de escalabilidad encaja bien dentro de un modelo de
microservicios.

Una de las cosas que hemos enfatizado a lo largo de este libro es que debería ser trivial generar nuevas instancias de
un microservicio. Luego, el microservicio adicional puede convertirse en otro servicio para procesar la cola de
mensajes. Este es un ejemplo de escalamiento horizontal.

Los mecanismos de escalado tradicionales para leer mensajes en una cola implicaban aumentar la cantidad de subprocesos
que un consumidor de mensajes podía procesar al mismo tiempo. Desafortunadamente, con este enfoque, en última instancia
estábamos limitados por la cantidad de CPU disponibles para el consumidor de mensajes. Un modelo de microservicio no
tiene esta limitación porque podemos escalar aumentando la cantidad de máquinas que alojan el servicio y consumen los
mensajes.

### Flexibilidad

El remitente de un mensaje no tiene idea de quién lo va a consumir. Esto significa que podemos agregar fácilmente nuevos
consumidores de mensajes (y nuevas funciones) sin afectar el servicio de envío original. Este es un concepto
extremadamente poderoso porque se pueden agregar nuevas funciones a una aplicación sin tener que tocar los servicios
existentes. En cambio, el nuevo código puede escuchar los eventos que se publican y reaccionar en consecuencia.

## Desventajas de una arquitectura de mensajería

Como cualquier modelo arquitectónico, una arquitectura basada en mensajes tiene sus ventajas y desventajas. Una
arquitectura basada en mensajes puede ser complicada y requiere que el equipo de desarrollo preste mucha atención a
varios aspectos clave, incluida la semántica del manejo de mensajes, la visibilidad de los mensajes y la coreografía de
los mensajes. Veámoslos con más detalle.

### Semántica del manejo de mensajes

El uso de mensajes en una aplicación basada en microservicios requiere más que comprender cómo publicar y consumir
mensajes. Requiere que comprendamos cómo se comportará nuestra aplicación según el orden en que se consumen los mensajes
y qué sucede si un mensaje se procesa fuera de orden. Por ejemplo, si tenemos requisitos estrictos de que todos los
pedidos de un solo cliente deben procesarse en el orden en que se reciben, necesitaremos configurar y estructurar
nuestro manejo de mensajes de manera diferente que si cada mensaje pudiera consumirse independientemente uno del otro.

También significa que si utilizamos la mensajería para imponer transiciones de estado estrictas de nuestros datos,
debemos pensar en diseñar nuestras aplicaciones para tener en cuenta escenarios en los que un mensaje genera una
excepción o un error se procesa fuera de orden. Si un mensaje falla, ¿volvemos a intentar procesar el error o dejamos
que falle? ¿Cómo manejamos los mensajes futuros relacionados con ese cliente si uno de los mensajes del cliente falla?
Éstas son preguntas importantes para reflexionar.

### Visibilidad del mensaje

El uso de mensajes en nuestros microservicios a menudo significa una combinación de llamadas de servicio sincrónicas y
procesamiento de servicios asincrónicos. La naturaleza asincrónica de los mensajes significa que es posible que no se
reciban ni procesen cerca del momento en que se publica o consume el mensaje. Además, tener elementos como ID de
correlación para rastrear las transacciones de un usuario a través de invocaciones y mensajes de servicios web es
fundamental para comprender y depurar lo que sucede en nuestra aplicación. Como recordará del capítulo 8, una ID de
correlación es un número único que se genera al inicio de la transacción de un usuario y se transmite con cada llamada
de servicio. También debe transmitirse junto con cada mensaje que se publique y consuma.

## Coreografía del mensaje

Como se mencionó en la sección sobre visibilidad de mensajes, una aplicación basada en mensajes hace que sea más difícil
razonar a través de su lógica de negocios porque su código ya no se procesa de manera lineal con un modelo de bloque
simple de solicitud-respuesta. En cambio, depurar aplicaciones basadas en mensajes puede implicar revisar los registros
de varios servicios diferentes, donde las transacciones de los usuarios pueden ejecutarse fuera de orden y en diferentes
momentos.

**NOTA**

> La mensajería puede ser complicada pero poderosa. En las secciones anteriores, no pretendíamos asustarte para que no
> uses la mensajería en tus aplicaciones. En cambio, nuestro objetivo era resaltar que el uso de la mensajería en sus
> servicios requiere previsión. Un lado positivo de la mensajería es que las propias empresas funcionan de forma
> asíncrona, por lo que, al final, modelamos nuestro negocio más de cerca.

## 10.2 Presentamos Spring Cloud Stream

`Spring Cloud` facilita la integración de mensajes en nuestros microservicios basados en Spring. Lo hace a través del
proyecto `Spring Cloud Stream` (https://spring.io/projects/spring-cloud-stream), que es un marco basado en anotaciones
que nos permite crear fácilmente publicadores y consumidores de mensajes en nuestras aplicaciones Spring.

`Spring Cloud Stream` también nos permite abstraer los detalles de implementación de la plataforma de mensajería que
estamos usando. Podemos usar múltiples plataformas de mensajes con `Spring Cloud Stream`, incluido el
proyecto `Apache Kafka` y `RabbitMQ`, y los detalles específicos de la implementación de la plataforma se mantienen
fuera del código de la aplicación. La implementación de la publicación y el consumo de mensajes en su aplicación se
realiza a través de interfaces Spring neutrales para la plataforma.

**NOTA**
> Para este capítulo, usaremos un bus de mensajes llamado Kafka (https://kafka.apache.org/). Kafka es un bus de mensajes
> de alto rendimiento que nos permite enviar flujos de mensajes de forma asincrónica desde una aplicación a una o más
> aplicaciones. Escrito en Java, Kafka es el bus de mensajes de facto para muchas aplicaciones basadas en la nube porque
> es altamente confiable y escalable. Spring Cloud Stream también admite el uso de RabbitMQ como bus de mensajes.

Para comprender `Spring Cloud Stream`, comencemos con una discusión de su arquitectura y familiaricémonos con cierta
terminología. La nueva terminología puede resultar algo abrumadora si nunca antes ha trabajado con una plataforma basada
en mensajes, así que comencemos nuestra discusión observando la arquitectura `Spring Cloud Stream` a través de la lente
de dos servicios que se comunican a través de mensajería. Un servicio es el publicador del mensaje y el otro servicio es
el consumidor del mensaje. La `Figura 10.3` muestra cómo se utiliza `Spring Cloud Stream` para facilitar el paso de este
mensaje.

![03.published-and-consumed.png](assets/chapter-10/03.published-and-consumed.png)

Con `Spring Cloud`, cuatro componentes participan en la publicación y el consumo de un mensaje:

- Source
- Channel
- Binder
- Sink

Cuando un servicio se prepara para publicar un mensaje, lo publicará utilizando una fuente. `Una fuente` es una interfaz
anotada por Spring que toma un `Plain Old Java Object (POJO), que representa el mensaje que se publicará`. La fuente
toma el mensaje, lo serializa (la serialización predeterminada es JSON) y publica el mensaje en un canal.

`Un canal` es una abstracción de la cola que contendrá el mensaje después de que lo publique un productor de mensajes o
lo consuma un consumidor de mensajes. En otras palabras, podemos describir `un canal` como una cola que envía y recibe
mensajes. Un nombre de canal siempre está asociado con un nombre de cola de destino, pero ese nombre de cola nunca está
expuesto directamente al código. En cambio, el nombre del canal se usa en el código, lo que significa que podemos
cambiar las colas desde las que lee o escribe el canal cambiando la configuración de la aplicación, no el código de la
aplicación.

El `binder` es parte del marco de trabajo `Spring Cloud Stream`. Es el código de Spring que se comunica con una
plataforma de mensajes específica. La parte del "binder" del marco de trabajo Spring Cloud Stream nos permite trabajar
con mensajes sin tener que estar expuestos a las bibliotecas y APIs específicas de la plataforma para publicar y
consumir mensajes.

En `Spring Cloud Stream`, cuando un servicio recibe un mensaje de una cola, lo hace a través de un `sink` (receptor).
Un `sink` (receptor) escucha un canal en busca de mensajes entrantes y deserializa el mensaje nuevamente en un objeto
POJO. A partir de ahí, el mensaje puede ser procesado por la lógica empresarial del servicio Spring.

## 10.3 Escribiendo un simple message producer y consumer

Ahora que hemos analizado los componentes esenciales de `Spring Cloud Stream`, veamos un ejemplo sencillo de
`Spring Cloud Stream`. Para el primer ejemplo, pasaremos un mensaje del servicio de nuestra organización a nuestro
servicio de licencias, que imprime un mensaje de registro en la consola. Además, debido a que en este ejemplo solo
tendremos una fuente de Spring Cloud Stream (el productor de mensajes) y un receptor (consumidor de mensajes),
comenzaremos el ejemplo con algunos atajos simples de Spring Cloud. Esto hará que sea trivial configurar la fuente en el
servicio de organización y en un receptor en el servicio de licencias. La `figura 10.4` destaca el productor de mensajes
y se basa en la arquitectura general de Spring Cloud Stream de la `figura 10.3`.

![04.organization-service-published-message.png](assets/chapter-10/04.organization-service-published-message.png)

## Configurando Apache Kafka y Redis en Docker

En esta sección, explicaremos cómo agregar los servicios `Kafka` y `Redis` a nuestro entorno `Docker` para nuestro
productor de mensajes. Para lograr esto, comencemos agregando el código que se muestra en la siguiente lista a nuestro
archivo `compose.yml`.

Mostraremos todos los servicios que tenemos hasta este momento el archivo `compose.yml`, eso incluye los nuevos
servicios de `Kafka` y `Redis` agregados. (Nota: Para que Kafka funcione, es importante agregar `Zookeeper`).

````yml
services:
  postgres_for_keycloak:
    image: postgres:15.2-alpine
    container_name: c-postgres-for-keycloak
    restart: unless-stopped
    environment:
      POSTGRES_DB: db_keycloak
      POSTGRES_USER: magadiflo
      POSTGRES_PASSWORD: magadiflo
    ports:
      - 5435:5432
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ 'CMD-SHELL', 'pg_isready -U magadiflo -d db_keycloak' ]
      interval: 10s
      timeout: 5s
      retries: 5

  keycloak:
    image: quay.io/keycloak/keycloak:21.0.2
    container_name: c-keycloak
    restart: unless-stopped
    command:
      - 'start-dev'
    ports:
      - 8181:8080
    depends_on:
      postgres_for_keycloak:
        condition: service_healthy
    environment:
      KC_DB: postgres
      KC_DB_URL_HOST: postgres_for_keycloak
      KC_DB_URL_DATABASE: db_keycloak
      KC_DB_USERNAME: magadiflo
      KC_DB_PASSWORD: magadiflo
      KC_DB_SCHEMA: public
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: c-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: [ "CMD-SHELL", "nc -z localhost 2181 || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: c-kafka
    restart: unless-stopped
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    ports:
      - 9092:9092
    depends_on:
      zookeeper:
        condition: service_healthy

  redis:
    image: redis:alpine
    container_name: c-redis
    ports:
      - 6379:6379

volumes:
  postgres_data:
    name: postgres_data
````

**NOTA**
> Los servicios de `Zookeeper` y `Kafka` agregados en el archivo `compose.yml` los he tomado del proyecto
> [microservices-e-commerce](https://github.com/magadiflo/microservices-e-commerce/blob/main/compose.yml), mientras que
> en el libro usan otras imágenes. Con respecto a `Redis`, la imagen sí es la misma.

## Levantando servicios de contenedores de docker

Teniendo hasta el momento todos los servicios mostrados en el archivo `compose.yml`, vamos a levantarlos para ver que
no ocurre ningún problema.

Nos posicionamos en la raíz del proyecto para ejecutar el siguiente comando:

````bash
M:\PROGRAMACION\DESARROLLO_JAVA_SPRING\08.book_ms-in-action-2021\spring-microservices-in-action-2021 (main -> origin)

$ docker compose -f .\docker\compose.yml up -d

[+] Running 7/7                              
 ✔ Network docker_default             Created
 ✔ Volume "postgres_data"             Created
 ✔ Container c-zookeeper              Healthy
 ✔ Container c-postgres-for-keycloak  Healthy
 ✔ Container c-redis                  Started
 ✔ Container c-keycloak               Started
 ✔ Container c-kafka                  Started
````

**NOTA**
> En la ejecución anterior usamos la bandera `-f`, esto es porque estamos posicionados en la raíz del proyecto y el
> archivo `compose.yml` no se encuentra en la raíz, sino más bien, se encuentra dentro del directorio `/docker`, por
> lo tanto debemos definir la ubicación de dicho archivo con la bandera `-f` seguido de la ruta y el
> archivo `compose.yml`.
>
> Si el archivo `compose.yml` estuviera en la raíz del proyecto desde donde estamos ejecutando los comandos, simplemente
> usaríamos como hemos venido usando hasta ahora: `docker compose up -d`.

Verificamos que todos los contenedores se hayan levantado sin problemas y estén con el `STATUS UP`.

````bash
$ docker container ls -a

CONTAINER ID   IMAGE                              COMMAND                  CREATED          STATUS                    PORTS                              NAMES
a6adef1f95e7   confluentinc/cp-kafka:7.4.0        "/etc/confluent/dock…"   13 minutes ago   Up 12 minutes             0.0.0.0:9092->9092/tcp             c-kafka
708fffd6004d   quay.io/keycloak/keycloak:21.0.2   "/opt/keycloak/bin/k…"   13 minutes ago   Up 12 minutes             8443/tcp, 0.0.0.0:8181->8080/tcp   c-keycloak
f93277432f2c   postgres:15.2-alpine               "docker-entrypoint.s…"   13 minutes ago   Up 13 minutes (healthy)   0.0.0.0:5435->5432/tcp             c-postgres-for-keycloak
2d1278ab609c   confluentinc/cp-zookeeper:7.4.0    "/etc/confluent/dock…"   13 minutes ago   Up 13 minutes (healthy)   2181/tcp, 2888/tcp, 3888/tcp       c-zookeeper
03dd862841e1   redis:alpine                       "docker-entrypoint.s…"   13 minutes ago   Up 13 minutes             0.0.0.0:6379->6379/tcp             c-redis
````

## Interceptando la solicitud HTTP entrante

Antes de continuar con la implementación de un producer para `Kafka`, necesitamos crea nuestro paquete `/utils` que
contendrá las mismas clases que usamos en el `licensing-sevice`: `UserContext`, `UserContextFilter`, `UserContextHolder`
y un `UserContextInterceptor`. Recordemos que la clase `UserContextFilter` nos ayudará a interceptar la solicitud Http y
a manipular el ID de correlación junto a otros atributos adicionales, para eso requerimos las otras clases.

Entonces, crearemos las clases antes mencionadas, dado que cuando lleguemos a implementar el producer para kafka,
requeriremos utilizar la información que serán almacenadas en la clase `UserContext`.

Empezaremos creando la clase `UserContext` en nuestro servicio `organization-service`:

````java

@Getter
@Setter
@Component
public class UserContext {

    public static final String CORRELATION_ID = "tmx-correlation-id";
    public static final String AUTH_TOKEN = "tmx-auth-token";
    public static final String USER_ID = "tmx-user-id";
    public static final String ORGANIZATION_ID = "tmx-organization-id";

    private String correlationId;
    private String authToken;
    private String userId;
    private String organizationId;

}
````

Ahora procedemos a crear la clase `UserContextHolder` quien contendrá un `ThreadLocal` del `UserContext`:

````java
public class UserContextHolder {

    private static final ThreadLocal<UserContext> threadLocal = new ThreadLocal<>();

    public static UserContext getContext() {
        UserContext userContext = threadLocal.get();
        if (userContext == null) {
            userContext = createEmptyContext();
            threadLocal.set(userContext);
        }
        return threadLocal.get();
    }

    public static void setUserContext(UserContext userContext) {
        Assert.notNull(userContext, "Sólo se permiten instancias de userContext no nulas");
        threadLocal.set(userContext);
    }

    public static UserContext createEmptyContext() {
        return new UserContext();
    }

}
````

Luego, creamos un filtro que se ejecutará cada vez que haya un request para poder recuperar del header el ID de
correlación y algunos atributos adicionales y almacenarlos en un `ThreadLocal` a través de la clase `UserContextHolder`.

````java

@Slf4j
@Component
public class UserContextFilter implements Filter {

    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        Filter.super.init(filterConfig);
    }

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)
            throws IOException, ServletException {

        HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;

        UserContextHolder.getContext().setCorrelationId(httpServletRequest.getHeader(UserContext.CORRELATION_ID));
        UserContextHolder.getContext().setUserId(httpServletRequest.getHeader(UserContext.USER_ID));
        UserContextHolder.getContext().setAuthToken(httpServletRequest.getHeader(UserContext.AUTH_TOKEN));
        UserContextHolder.getContext().setOrganizationId(httpServletRequest.getHeader(UserContext.ORGANIZATION_ID));

        log.debug("Servicio de organización - ID de correlación entrante: {}", UserContextHolder.getContext().getCorrelationId());

        filterChain.doFilter(httpServletRequest, servletResponse);
    }

    @Override
    public void destroy() {
        Filter.super.destroy();
    }
}
````

Para finalizar este paquete de clases, crearemos la clase interceptora que podríamos usarlo cuando este microservicio
de organización realice alguna petición a algún otro microservicio enviándole el ID de correlación y otros atributos
más que se requieran enviar.

````java

@Slf4j
public class UserContextInterceptor implements ClientHttpRequestInterceptor {

    @Override
    public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution)
            throws IOException {

        HttpHeaders headers = request.getHeaders();
        headers.add(UserContext.CORRELATION_ID, UserContextHolder.getContext().getCorrelationId());
        headers.add(UserContext.AUTH_TOKEN, UserContextHolder.getContext().getAuthToken());

        log.debug("[organization-service: Interceptor] Agregando al header {}: {}", UserContext.CORRELATION_ID, UserContextHolder.getContext().getCorrelationId());
        log.debug("[organization-service: Interceptor] Agregando al header {}: {}", UserContext.AUTH_TOKEN, UserContextHolder.getContext().getAuthToken());

        return execution.execute(request, body);
    }
}
````

## Escribir el productor de mensajes en el servicio de organización

Para centrarnos en cómo utilizar los `topics` en nuestra arquitectura, comenzaremos modificando el servicio de
organización para que cada vez que se `agregue, actualice o elimine` datos de una organización, el servicio de
organización publique un mensaje en un `topic de Kafka`, indicando que ha ocurrido un evento de cambio en la
organización. El mensaje publicado incluirá el `ID de la organización` asociado con el evento de cambio y qué acción
ocurrió (agregar, actualizar o eliminar).

Lo primero que necesitamos hacer es configurar nuestras dependencias de Maven en el archivo `pom.xml` del servicio de
organización.

````xml

<dependencies>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>
````

**IMPORTANTE**

> En el libro se utilizan las dependencias `spring-cloud-stream` y `spring-cloud-starter-stream-kafka`. Luego, en el
> código implementado usan anotaciones como `@EnableBinding(Source.class)`, `@EnableBinding(Sink.class)`, mismas
> que se encuentran deprecadas en favor del uso de programación funcional.
>
> En mi caso, usaré directamente la dependencia de `Spring for Apache Kafka`. En ese sentido, la implementación que
> que haré puede variar un tanto al del libro, pero la idea va a ser la
> misma `"que un publicador, envíe mensajes a un topic y un consumidor esté atento a dichos mensajes"`.

Vamos a crear el topic `org-change-topic` a donde serán publicados los mensajes por nuestro servicio de organización:

````java

@Configuration
public class KafkaOrganizationTopicConfig {

    public final static String ORG_CHANGE_TOPIC = "org-change-topic";

    @Bean
    public NewTopic topic() {
        return TopicBuilder.name(ORG_CHANGE_TOPIC).build();
    }
}
````

En el siguiente paso crearemos la lógica para publicar el mensaje en el topic creado anteriormente.

````java

@Slf4j
@RequiredArgsConstructor
@Component
public class OrganizationProducer {

    private final KafkaTemplate<String, OrganizationChangeModel> kafkaTemplate;

    public void publishOrganizationChange(ActionEnum action, String organizationId) {
        log.debug("Enviando mensaje a Kafka {} para el organizationId {}", action, organizationId);

        OrganizationChangeModel organizationChangeModel = new OrganizationChangeModel(
                action.name(),
                organizationId,
                UserContextHolder.getContext().getCorrelationId());

        Message<OrganizationChangeModel> message = MessageBuilder
                .withPayload(organizationChangeModel)
                .setHeader(KafkaHeaders.TOPIC, KafkaOrganizationTopicConfig.ORG_CHANGE_TOPIC)
                .build();

        this.kafkaTemplate.send(message);
    }

}
````

El `ActionEnum` pasado por parámetro en el método `publishOrganizationChange()` contiene las siguientes acciones:

````java
public enum ActionEnum {
    GET,
    CREATED,
    UPDATED,
    DELETED
}
````

La publicación real del mensaje se produce en el método `publishOrganizationChange()`. Este método construye un `POJO`
de Java llamado `OrganizationChangeModel`. El siguiente listado muestra el código de este POJO.

````java
public record OrganizationChangeModel(String action,
                                      String organizationId,
                                      String correlationId) {
}
````

La clase `OrganizationChangeModel` declara tres elementos de datos:

- `action`: esta es la acción que desencadenó el evento. Hemos incluido el elemento de acción en el mensaje para
  brindarle al consumidor del mensaje más contexto sobre cómo debe procesar un evento.
- `organizationId`: este es el ID de la organización asociado con el evento.
- `correlationId`: este es el ID de correlación de la llamada de servicio que desencadenó el evento. Siempre debemos
  incluir un ID de correlación en nuestros eventos, ya que ayuda enormemente a rastrear y depurar el flujo de mensajes
  a través de nuestros servicios.

El método `send()` toma una clase `Spring Message`. Usamos una clase auxiliar de `Spring`, llamada `MessageBuilder`,
para tomar el contenido de la clase `OrganizationChangeModel` y convertirlo en una clase `Spring Message`. Este es todo
el código que necesitamos para enviar un mensaje. Sin embargo, aún nos falta agregar la configuración de kafka como un
`producer` en el archivo de configuración de este microservicio.

````yml
spring:
  kafka:
    producer:
      bootstrap-servers: localhost:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      properties:
        spring.json.type.mapping: organizationChangeToken:dev.magadiflo.organization.app.model.dto.OrganizationChangeModel
````

El objeto que enviaremos al topic de kafka será del tipo `OrganizationChangeModel`, por lo tanto, usamos como
serializador el `JsonSerializer`. Además, estamos mapeando la clase `OrganizationChangeModel` al un token
`organizationChangeToken`. De esta manera, cuando implementemos el consumer también usaremos el mismo token y lo
mapearemos a una clase similar a la que aquí estamos usamos `(OrganizationChangeModel)` con la finalidad de poder
recibir los datos que estamos enviando desde este producer.

Para mayor información sobre el uso de la configuración `spring.json.type.mapping` visitar la siguiente referencia
donde explico a mayor detalle el funcionamiento.

**Referencia**

- [microservices-e-commerce](https://github.com/magadiflo/microservices-e-commerce/blob/main/business-domain/order-service/README.md#agrega-dependencia-de-kafka)

Ahora que tenemos el código que publicará un mensaje a través de `Spring for Apache Kafka`, veamos dónde ocurre
realmente la publicación del mensaje en el servicio de nuestra organización. La clase `OrganizationService` hará esto
por nosotros. Para cada método del servicio que cambia los datos de la organización, llamaremos al
`this.organizationProducer.publishOrganizationChange(...)`.

````java

@RequiredArgsConstructor
@Service
public class OrganizationService {

    private final OrganizationRepository organizationRepository;
    private final Environment environment;
    private final OrganizationProducer organizationProducer;

    @Transactional(readOnly = true)
    public Organization findById(String organizationId) {
        return this.organizationRepository.findById(organizationId)
                .map(organizationDB -> {
                    Integer port = Integer.parseInt(Objects.requireNonNull(this.environment.getProperty("local.server.port")));
                    organizationDB.setPort(port);

                    this.organizationProducer.publishOrganizationChange(ActionEnum.GET, organizationId);
                    return organizationDB;
                })
                .orElseThrow(() -> new NoSuchElementException("No existe la Organización con el id %s".formatted(organizationId)));
    }

    @Transactional
    public Organization create(Organization organization) {
        organization.setOrganizationId(UUID.randomUUID().toString());
        Organization organizationDB = this.organizationRepository.save(organization);
        this.organizationProducer.publishOrganizationChange(ActionEnum.CREATED, organizationDB.getOrganizationId());
        return organizationDB;
    }

    @Transactional
    public Organization update(Organization organization, String organizationId) {
        return this.organizationRepository.findById(organizationId)
                .map(organizationDB -> {
                    organizationDB.setName(organization.getName());
                    organizationDB.setContactName(organization.getContactName());
                    organizationDB.setContactEmail(organization.getContactEmail());
                    organizationDB.setContactPhone(organization.getContactPhone());
                    return organizationDB;
                })
                .map(organizationDB -> {
                    this.organizationRepository.save(organizationDB);
                    this.organizationProducer.publishOrganizationChange(ActionEnum.UPDATED, organizationId);
                    return organizationDB;
                })
                .orElseThrow(() -> new NoSuchElementException("No hay organizació con id %s para actualizar".formatted(organizationId)));
    }

    @Transactional
    public void delete(String organizationId) {
        this.organizationRepository.deleteById(organizationId);
        this.organizationProducer.publishOrganizationChange(ActionEnum.DELETED, organizationId);
    }
}
````

**¿Qué datos debo poner en el mensaje?**

> Una de las preguntas más comunes que recibimos de los equipos cuando se embarcan por primera vez en el viaje del
> mensaje es: ¿exactamente cuántos datos debo incluir en el mensaje? Nuestra respuesta es que depende de su aplicación.
>
> Como habrás notado, en todos nuestros ejemplos, solo devolvemos el ID de la organización del registro de la
> organización que ha cambiado. Nunca ponemos una copia de los cambios de datos en el mensaje. Además, utilizamos
> mensajes basados en eventos del sistema para informar a otros servicios que el estado de los datos ha cambiado y
> siempre obligamos a los otros servicios a volver al maestro (el servicio propietario de los datos) para recuperar una
> nueva copia de los datos. Este enfoque es más costoso en términos de tiempo de ejecución, pero garantiza que siempre
> tendremos la última copia de los datos. Pero existe una pequeña posibilidad de que los datos con los que trabajamos
> cambien inmediatamente después de haberlos leído desde el sistema fuente. Sin embargo, es mucho menos probable que eso
> ocurra que si consumimos ciegamente la información directamente de la cola.
>
> Nuestro consejo es que piense detenidamente sobre la cantidad de datos que está transmitiendo. Tarde o temprano, se
> encontrará con una situación en la que los datos pasados estén "obsoletos". Podría deberse a que un problema hizo
> que permaneciera demasiado tiempo en la cola de mensajes, o que un mensaje anterior que contenía datos falló y los
> datos que está pasando en el mensaje ahora representan datos en un estado inconsistente. Esto podría deberse a que su
> aplicación se basó en el estado del mensaje en lugar del estado real del almacén de datos subyacente. Si va a pasar el
> estado en su mensaje, asegúrese de incluir una marca de fecha y hora o un número de versión para que el servicio que
> consume los datos pueda inspeccionar los datos que se le pasan y asegurarse de que no sean más antiguos que la copia
> de datos que ya tiene.

## Probando el envío del mensaje al topic de Kafka

Levantamos todos los proyectos en el siguiente orden:

1. config-server
2. eureka-server
3. licensing-service y organization-service (aquí el orden no importa)
4. gateway-server

Antes de realizar alguna petición al backend, vamos a dejar activo un `kafka consumer` que nos proporciona kafka para
realizar pruebas. Así que ingresamos dentro del contenedor de kafka y ejecutamos el siguiente comando:

````bash
$ docker container exec -it c-kafka /bin/sh

sh-4.4$ kafka-console-consumer --topic org-change-topic --bootstrap-server localhost:9092
````

El comando anterior hará que el kafka consumer esté atento a algún mensaje que llegue al topic `org-change-topic`. Este
topic fue creado cuando levantamos el microservicio de `organization-service` y se ejecutó el bean `NewTopic`.

Luego, como nuestros microservicios están segurizados con Keycloak, necesitamos generar un token para realizar una
petición exitosa, por lo tanto, primero generaremos el token de la siguiente manera:

````bash
$ curl -v -X POST -u ostock:UHfnnjt8hC2WC9rehLkXKe9BAOBQQvRm -d "grant_type=password&username=illary.huaylupo&password=123456" http://keycloak:8181/realms/spmia-realm/protocol/openid-connect/token | jq
>
< HTTP/1.1 200 OK
< Referrer-Policy: no-referrer
< X-Frame-Options: SAMEORIGIN
< Strict-Transport-Security: max-age=31536000; includeSubDomains
< Cache-Control: no-store
< X-Content-Type-Options: nosniff
< Set-Cookie: KEYCLOAK_LOCALE=; Version=1; Comment=Expiring cookie; Expires=Thu, 01-Jan-1970 00:00:10 GMT; Max-Age=0; Path=/realms/spmia-realm/; HttpOnly
< Set-Cookie: KC_RESTART=; Version=1; Expires=Thu, 01-Jan-1970 00:00:10 GMT; Max-Age=0; Path=/realms/spmia-realm/; HttpOnly
< Pragma: no-cache
< X-XSS-Protection: 1; mode=block
< Content-Type: application/json
< content-length: 2372
<
{
  "access_token": "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJwekEwNTNXY2tGeXc4TEtDQk5qWk0wbjRnLVdhSkhwYTRiSTVkZjNWdW9nIn0.eyJleHAiOjE3MjEyODExOTMsImlhdCI6MTcyMTI4MDg5MywianRpIjoiODMwMzBkOGYtNzNhYS00YjA2LTgzMjctMjg0ZTU1ZDliODNlIiwiaXNzIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwiYXVkIjoiYWNjb3VudCIsInN1YiI6Ijc0YmQ1NDQ2LTA4NWQtNDU1NC04MGYyLTA1MDEzZjI0MGMzMiIsInR5cCI6IkJlYXJlciIsImF6cCI6Im9zdG9jayIsInNlc3Npb25fc3RhdGUiOiIzNWIzMGI3OS1hNzc0LTQ2MjYtYjViZC0wYWIzMmZiOTE4M2MiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIioiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwiZGVmYXVsdC1yb2xlcy1zcG1pYS1yZWFsbSIsInVtYV9hdXRob3JpemF0aW9uIiwib3N0b2NrLWFkbWluIiwib3N0b2NrLXVzZXIiXX0sInJlc291cmNlX2FjY2VzcyI6eyJvc3RvY2siOnsicm9sZXMiOlsiQURNSU4iLCJVU0VSIl19LCJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiIzNWIzMGI3OS1hNzc0LTQ2MjYtYjViZC0wYWIzMmZiOTE4M2MiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmFtZSI6IklsYXJ5IEh1YXlsdXBvIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiaWxsYXJ5Lmh1YXlsdXBvIiwiZ2l2ZW5fbmFtZSI6IklsYXJ5IiwiZmFtaWx5X25hbWUiOiJIdWF5bHVwbyIsImVtYWlsIjoiaWxsYXJ5Lmh1YXlsdXBvQGdtYWlsLmNvbSJ9.PP001_hW7JeZcBCUgVuh5Xz_vLIwiTNv0bBr7IigQX5ZhVaQAtwSePhtQt4q6wEvVS8EdCCg9y4f8OaNL0IkZuZNOxREZw-Wv5Pi8T4JwqtzOrXQhvQiLKYEbMy4pm-FgU2Yg0eZxn9IfG7AAAXaSkIkRuHOCDS87a8zsXCvOcYSppfy34xpXCUkbCyykLKaa0kSjVhhpXuoC2WmqhVCyZzPqFDsrVuZQKzmU8D3KltihzUuBe0UxfbaJQraFzFuj1zAZNKRlYFyaUvAk_vlTn74bN4kZs54Emm0B0ChntwJGjZ5nIG9eeOZlxVDEcD_KeAZ4mJDoHIR4rg_ouhElA",
  "expires_in": 300,
  "refresh_expires_in": 1800,
  "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJkMzEyZTdjZC1jZjBiLTRlMDgtOTgxMS1hYzNkMWI3ZWM2MDMifQ.eyJleHAiOjE3MjEyODI2OTMsImlhdCI6MTcyMTI4MDg5MywianRpIjoiNzZkODU2ZTktNGZlYy00NTg5LThiOTQtMDQ0ZmMwYzc3OGYwIiwiaXNzIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwiYXVkIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwic3ViIjoiNzRiZDU0NDYtMDg1ZC00NTU0LTgwZjItMDUwMTNmMjQwYzMyIiwidHlwIjoiUmVmcmVzaCIsImF6cCI6Im9zdG9jayIsInNlc3Npb25fc3RhdGUiOiIzNWIzMGI3OS1hNzc0LTQ2MjYtYjViZC0wYWIzMmZiOTE4M2MiLCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiIzNWIzMGI3OS1hNzc0LTQ2MjYtYjViZC0wYWIzMmZiOTE4M2MifQ.vCKdXNqxUp4fYUiy-CZ2KDRkltH8cECkpJWxAuPmOZM",
  "token_type": "Bearer",
  "not-before-policy": 0,
  "session_state": "35b30b79-a774-4626-b5bd-0ab32fb9183c",
  "scope": "profile email"
}
````

**NOTA**
> Posiblemente, el password del cliente que generamos en keycloak haya cambiado hasta este punto del tutorial, dado que
> he vuelto a crear el cliente. Lo importante es que requerimos credenciales del cliente que ya tenemos registrado en
> keycloak.

Con el access token obtenido, realizamos una petición que recupere la licencia e internamente llame al microservicio
de organización para consultar por el organizationId.

````bash
$ curl -v -H "Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJwekEwNTNXY2tGeXc4TEtDQk5qWk0wbjRnLVdhSkhwYTRiSTVkZjNWdW9nIn0.eyJleHAiOjE3MjEyODExOTMsImlhdCI6MTcyMTI4MDg5MywianRpIjoiODMwMzBkOGYtNzNhYS00YjA2LTgzMjctMjg0ZTU1ZDliODNlIiwiaXNzIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwiYXVkIjoiYWNjb3VudCIsInN1YiI6Ijc0YmQ1NDQ2LTA4NWQtNDU1NC04MGYyLTA1MDEzZjI0MGMzMiIsInR5cCI6IkJlYXJlciIsImF6cCI6Im9zdG9jayIsInNlc3Npb25fc3RhdGUiOiIzNWIzMGI3OS1hNzc0LTQ2MjYtYjViZC0wYWIzMmZiOTE4M2MiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIioiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwiZGVmYXVsdC1yb2xlcy1zcG1pYS1yZWFsbSIsInVtYV9hdXRob3JpemF0aW9uIiwib3N0b2NrLWFkbWluIiwib3N0b2NrLXVzZXIiXX0sInJlc291cmNlX2FjY2VzcyI6eyJvc3RvY2siOnsicm9sZXMiOlsiQURNSU4iLCJVU0VSIl19LCJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiIzNWIzMGI3OS1hNzc0LTQ2MjYtYjViZC0wYWIzMmZiOTE4M2MiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmFtZSI6IklsYXJ5IEh1YXlsdXBvIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiaWxsYXJ5Lmh1YXlsdXBvIiwiZ2l2ZW5fbmFtZSI6IklsYXJ5IiwiZmFtaWx5X25hbWUiOiJIdWF5bHVwbyIsImVtYWlsIjoiaWxsYXJ5Lmh1YXlsdXBvQGdtYWlsLmNvbSJ9.PP001_hW7JeZcBCUgVuh5Xz_vLIwiTNv0bBr7IigQX5ZhVaQAtwSePhtQt4q6wEvVS8EdCCg9y4f8OaNL0IkZuZNOxREZw-Wv5Pi8T4JwqtzOrXQhvQiLKYEbMy4pm-FgU2Yg0eZxn9IfG7AAAXaSkIkRuHOCDS87a8zsXCvOcYSppfy34xpXCUkbCyykLKaa0kSjVhhpXuoC2WmqhVCyZzPqFDsrVuZQKzmU8D3KltihzUuBe0UxfbaJQraFzFuj1zAZNKRlYFyaUvAk_vlTn74bN4kZs54Emm0B0ChntwJGjZ5nIG9eeOZlxVDEcD_KeAZ4mJDoHIR4rg_ouhElA" http://localhost:8072/license/v1/organization/optimaGrowth/license/a9c7901b-6f0c-4ec7-b42c-fcb483062c17/restClient | jq
>
< HTTP/1.1 200 OK
< transfer-encoding: chunked
< Vary: Origin
< Vary: Access-Control-Request-Method
< Vary: Access-Control-Request-Headers
< X-Content-Type-Options: nosniff
< X-XSS-Protection: 0
< Cache-Control: no-cache, no-store, max-age=0, must-revalidate
< Pragma: no-cache
< Expires: 0
< X-Frame-Options: DENY
< Content-Type: application/hal+json
< Date: Thu, 18 Jul 2024 05:37:14 GMT
< tmx-correlation-id: 14ec615b-12a5-42b8-997e-c633bd6f861b
<
{
  "licenseId": "a9c7901b-6f0c-4ec7-b42c-fcb483062c17",
  "description": "Licencia full",
  "organizationId": "optimaGrowth",
  "productName": "Spring Boot v3.2.5",
  "licenseType": "full",
  "comment": "[classpath:/config] licensing-service-dev.yml: DEV",
  "organizationName": "Casa de la mujer",
  "contactName": "Paul Herrera",
  "contactPhone": "943857458",
  "contactEmail": "paul@gmail.com",
  "port": 62526
}
````

Ahora, si verificamos la consola del `kafka consumer` veremos que el mensaje ha llegado correctamente.

````bash
$ docker container exec -it c-kafka /bin/sh

sh-4.4$ kafka-console-consumer --topic org-change-topic --bootstrap-server localhost:9092
{"type":"dev.magadiflo.organization.app.model.dto.OrganizationChangeModel","action":"GET","organizationId":"optimaGrowth","correlationId":"14ec615b-12a5-42b8-997e-c633bd6f861b"}
````

## Escribir el consumidor de mensajes en el servicio de licencias

En este punto, hemos modificado el servicio de organización para publicar un mensaje en Kafka cada vez que el servicio
de organización cambia datos. Cualquier servicio interesado puede reaccionar sin necesidad de ser llamado explícitamente
por el servicio de la organización.

Ahora cambiemos de dirección y veamos cómo un servicio puede consumir un mensaje usando `Spring for Apache Kafka`.
Para este ejemplo, el servicio de licencias consumirá el mensaje publicado por el servicio de la organización.
Para comenzar, debemos agregar nuestras dependencias de `Spring for Apache Kafka` al archivo `pom.xml` de servicios de
licencia.

La figura siguiente muestra cómo es que encaja el servicio de licencia con el uso de `Spring Cloud Stream`.

![05.consuming-message.png](assets/chapter-10/05.consuming-message.png)

**NOTA**
> La imagen anterior (`Figure 10.5`) corresponde a la arquitectura mostrada por `Spring Cloud Stream`. En mi caso,
> estoy usando directamente `Spring for Apache Kafka` como dependencia, por lo tanto, puede que sea distinta a la que
> se muestra en la imagen, dado que no he investigado sobre el mismo. Así que aclaro que la imagen que estoy colocando,
> es la imagen que se muestra en el libro con el uso de `Spring Cloud Stream`. En mi caso, uso
> `Spring for Apache Kafka`, pero la imagen lo muestro porque sirve para graficar lo que también hace la dependencia
> que estoy usando. En este caso, consumir mensajes desde el topic de kafka.

Como mencionamos, en mi caso estoy usando `Spring for Apache Kafka`, por lo tanto, esa dependencia lo agregaremos al
`pom.xml` del servicio de licencias.

````xml

<dependencies>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>
````

A continuación, crearemos un dto al que se mapeará el objeto que recibamos del topic de kafka.

````java
public record OrganizationChange(String action,
                                 String organizationId,
                                 String correlationId) {
}
````

Luego, crearemos nuestra clase especializada en la escucha de los mensajes que se envían al topic de kafaka.

````java

@Slf4j
@RequiredArgsConstructor
@Component
public class LicensingConsumer {

    @KafkaListener(topics = "org-change-topic", groupId = "licensing-group")
    public void consumeOrganizationChange(OrganizationChange organizationChange) {
        log.debug("Se recibió el evento {} para el ID de la organización {} con id de correlación {}",
                organizationChange.action(), organizationChange.organizationId(), organizationChange.correlationId());
    }

}
````

**El concepto de grupo de consumidores es el siguiente:** podemos tener múltiples servicios y cada servicio tiene
múltiples instancias escuchando la misma cola de mensajes. Queremos que cada servicio único procese una copia de un
mensaje, pero solo queremos que una instancia de servicio dentro de un grupo de instancias de servicio consuma y procese
un mensaje. La propiedad `gropuId` identifica el grupo de consumidores al que pertenece el servicio.

Siempre que todas las instancias de servicio tengan el mismo nombre de grupo, `Spring for Apache Kafka` garantizará que
una instancia de servicio que pertenezca a ese grupo consumirá solo una copia del mensaje. En el caso de nuestro
servicio de licencias, llamaremos al grupoId `licensing-group`. La `Figura 10.6` ilustra cómo este grupo de
consumidores ayuda a imponer el consumo una vez que se satisface la semántica de un mensaje consumido en múltiples
servicios.

![06.consumer-group.png](assets/chapter-10/06.consumer-group.png)

Para finalizar la implementación del consumer debemos agregar la siguiente configuración en el archivo de propiedades
`licensing-service.yml` ubicado en el servidor de configuración `Spring Cloud Config Server`:

````yml
spring:
  kafka:
    consumer:
      bootstrap-servers: localhost:9092
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: '*'
        spring.json.type.mapping: organizationChangeToken:dev.magadiflo.licensing.app.model.dto.OrganizationChange
````

Notar que, en la configuración `spring.json.type.mapping` estamos usando el mismo token `organizationChangeToken`
que usamos en la configuración del `producer` del servicio de organización. La diferencia es que aquí ese token lo
vamos a mapear a su correspondiente objeto DTO que se ubica en la ruta que se muestra. Recordar que eso lo hacemos
para que los datos enviados en json se mapeen a un objeto de java.

## Viendo el servicio de mensaje en acción

En este punto, el servicio de la organización publica un mensaje en `org-change-topic` cada vez que se
`agrega`, `actualiza` o `elimina` un registro (también agregamos en la parte donde se consulta un registro),
y el servicio de licencias recibe el mensaje desde el mismo topic `org-change-topic`. A continuación, veremos este
código en acción creando un registro de servicio en la organización y observando la consola para ver el mensaje de
registro correspondiente en el servicio de licencias.

Recordar que primero debemos generar un access token para poder realizar peticiones al backend:

````bash
$ curl -v -X POST -u ostock:8G7wLN1G5o6Dfw5mWfvqD6Dax1qf7Znx -d "grant_type=password&username=illary.huaylupo&password=123456" http://keycloak:8181/realms/spmia-realm/protocol/openid-connect/token | jq
>
< HTTP/1.1 200 OK
<
{
  "access_token": "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJxTWNNYzlGaFI4bmxPb0xUYkw3R01SVmt1MVJHNmd3b1FhWDJQazBCcFlZIn0.eyJleHAiOjE3MjEzNjcyOTcsImlhdCI6MTcyMTM2Njk5NywianRpIjoiNDY3OTljYjYtYTVhZC00NTQzLTk1MTQtNjliMGNiYTBiODZjIiwiaXNzIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwiYXVkIjoiYWNjb3VudCIsInN1YiI6ImM2OGJlZGVmLWNmYWYtNGU4My05NTk2LWE2NGUzMjhmZGEyOSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im9zdG9jayIsInNlc3Npb25fc3RhdGUiOiI4ODA2YmU1Ni1lNTY3LTQyMTItYTUyNi04YjgwZjc3N2FlMzkiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIioiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwiZGVmYXVsdC1yb2xlcy1zcG1pYS1yZWFsbSIsInVtYV9hdXRob3JpemF0aW9uIiwib3N0b2NrLWFkbWluIiwib3N0b2NrLXVzZXIiXX0sInJlc291cmNlX2FjY2VzcyI6eyJvc3RvY2siOnsicm9sZXMiOlsiQURNSU4iLCJVU0VSIl19LCJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiI4ODA2YmU1Ni1lNTY3LTQyMTItYTUyNi04YjgwZjc3N2FlMzkiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmFtZSI6IklsYXJ5IEh1YXlsdXBvIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiaWxsYXJ5Lmh1YXlsdXBvIiwiZ2l2ZW5fbmFtZSI6IklsYXJ5IiwiZmFtaWx5X25hbWUiOiJIdWF5bHVwbyIsImVtYWlsIjoiaWxsYXJ5Lmh1YXlsdXBvQGdtYWlsLmNvbSJ9.dQ54ShzjToBebOwBzwKnM--qJwZs2PF0gqazEYMxCw28-IZG5FW8AUWdQ-lCDYo2dTBo0iJgv651To_BnME0ST9uiJOTvIDhEHXNnVjqjuQFkHytlMiXSpDrhOZols1CE_yld-7xQAEqzgbhXKdVyRRgD-nRECIRyMROeAG83IyHsEs55L72UCP-L9VWVjF4B3oAsYPD2uDRPVHzkGEgfXWOGt5c2iXxfuvRQGVidBI2rehKHD1RM6ZT-6ziP3hLioKKQmYnPfImDcHJC6sX7LoWDHaQWM-7kDMBLyklaxmSFDaivL7PvTxYv_e9K7C1q1KKOy9Vp1O50hl6AaeSAQ",
  "expires_in": 300,
  "refresh_expires_in": 1800,
  "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJhYWEyMWYzNy01MjNmLTQwOGQtOWQ3NS04ZDNjMGFiYmQzOWQifQ.eyJleHAiOjE3MjEzNjg3OTcsImlhdCI6MTcyMTM2Njk5NywianRpIjoiMDk1MmJiMTQtODI4OC00NTczLWEzYTctZTYzNWI1MThhZTEwIiwiaXNzIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwiYXVkIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwic3ViIjoiYzY4YmVkZWYtY2ZhZi00ZTgzLTk1OTYtYTY0ZTMyOGZkYTI5IiwidHlwIjoiUmVmcmVzaCIsImF6cCI6Im9zdG9jayIsInNlc3Npb25fc3RhdGUiOiI4ODA2YmU1Ni1lNTY3LTQyMTItYTUyNi04YjgwZjc3N2FlMzkiLCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiI4ODA2YmU1Ni1lNTY3LTQyMTItYTUyNi04YjgwZjc3N2FlMzkifQ.040A1Xq3LkeeiJZPF8j-RaAG4EzzYs40VMwQe3efhkQ",
  "token_type": "Bearer",
  "not-before-policy": 0,
  "session_state": "8806be56-e567-4212-a526-8b80f777ae39",
  "scope": "profile email"
}
````

A continuación, usando el access token anterior, registramos una nueva organización realizando una llamada al servicio
de organización:

````bash
$ curl -v -H "Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJxTWNNYzlGaFI4bmxPb0xUYkw3R01SVmt1MVJHNmd3b1FhWDJQazBCcFlZIn0.eyJleHAiOjE3MjEzNjcyOTcsImlhdCI6MTcyMTM2Njk5NywianRpIjoiNDY3OTljYjYtYTVhZC00NTQzLTk1MTQtNjliMGNiYTBiODZjIiwiaXNzIjoiaHR0cDovL2tleWNsb2FrOjgxODEvcmVhbG1zL3NwbWlhLXJlYWxtIiwiYXVkIjoiYWNjb3VudCIsInN1YiI6ImM2OGJlZGVmLWNmYWYtNGU4My05NTk2LWE2NGUzMjhmZGEyOSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im9zdG9jayIsInNlc3Npb25fc3RhdGUiOiI4ODA2YmU1Ni1lNTY3LTQyMTItYTUyNi04YjgwZjc3N2FlMzkiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIioiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwiZGVmYXVsdC1yb2xlcy1zcG1pYS1yZWFsbSIsInVtYV9hdXRob3JpemF0aW9uIiwib3N0b2NrLWFkbWluIiwib3N0b2NrLXVzZXIiXX0sInJlc291cmNlX2FjY2VzcyI6eyJvc3RvY2siOnsicm9sZXMiOlsiQURNSU4iLCJVU0VSIl19LCJhY2NvdW50Ijp7InJvbGVzIjpbIm1hbmFnZS1hY2NvdW50IiwibWFuYWdlLWFjY291bnQtbGlua3MiLCJ2aWV3LXByb2ZpbGUiXX19LCJzY29wZSI6InByb2ZpbGUgZW1haWwiLCJzaWQiOiI4ODA2YmU1Ni1lNTY3LTQyMTItYTUyNi04YjgwZjc3N2FlMzkiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmFtZSI6IklsYXJ5IEh1YXlsdXBvIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiaWxsYXJ5Lmh1YXlsdXBvIiwiZ2l2ZW5fbmFtZSI6IklsYXJ5IiwiZmFtaWx5X25hbWUiOiJIdWF5bHVwbyIsImVtYWlsIjoiaWxsYXJ5Lmh1YXlsdXBvQGdtYWlsLmNvbSJ9.dQ54ShzjToBebOwBzwKnM--qJwZs2PF0gqazEYMxCw28-IZG5FW8AUWdQ-lCDYo2dTBo0iJgv651To_BnME0ST9uiJOTvIDhEHXNnVjqjuQFkHytlMiXSpDrhOZols1CE_yld-7xQAEqzgbhXKdVyRRgD-nRECIRyMROeAG83IyHsEs55L72UCP-L9VWVjF4B3oAsYPD2uDRPVHzkGEgfXWOGt5c2iXxfuvRQGVidBI2rehKHD1RM6ZT-6ziP3hLioKKQmYnPfImDcHJC6sX7LoWDHaQWM-7kDMBLyklaxmSFDaivL7PvTxYv_e9K7C1q1KKOy9Vp1O50hl6AaeSAQ" -H "Content-Type: application/json" -d "{\"name\": \"Ostock\", \"contactName\": \"Illary Huaylupo\", \"contactEmail\": \"illaryhs@gmail.com\", \"contactPhone\": \"888888888\"}" http://localhost:8072/organization/v1/organization | jq
>
< HTTP/1.1 201 Created
<
{
  "organizationId": "20533797-b851-4efe-b541-69cee1772637",
  "name": "Ostock",
  "contactName": "Illary Huaylupo",
  "contactEmail": "illaryhs@gmail.com",
  "contactPhone": "888888888",
  "port": null
}
````

Ahora, revisamos la consola del `organization-service` vemos dos registros de `log` importantes, la primera el mensaje
de que se está publicando el mensaje al topic de kafka y el segundo la inserción del registro en la base de datos.

````bash
d.m.o.app.kafka.OrganizationProducer     : Enviando mensaje a Kafka CREATED para el organizationId 20533797-b851-4efe-b541-69cee1772637
org.hibernate.SQL                        : 
    insert 
    into
        organizations
        (contact_email, contact_name, contact_phone, name, organization_id) 
    values
        (?, ?, ?, ?, ?)
````

Como se ha ha publicado un mensaje en el tópico de kafka, nuestro `licensing-service` tiene un oyente que está
escuchando los mensajes que le llegan a dicho tópico, por lo tanto, en consola veremos que efectivamente nuestro
`licensing-service` acaba de recibir el mensaje del `topic`:

````bash
d.m.l.app.kafka.LicensingConsumer        : Se recibió el evento CREATED para el ID de la organización 20533797-b851-4efe-b541-69cee1772637 con id de correlación d1e6f0fc-1f72-4995-9270-17ef18b774cf
````

Ahora tenemos dos servicios que se comunican entre sí mediante mensajes. `Spring for Apache Kafka` actúa como
intermediario para estos servicios. Desde la perspectiva de la mensajería, los servicios no saben nada entre sí. Están
utilizando un `broker de mensajería` como intermediario para comunicarse y `Spring for Apache Kafka` como una capa de
abstracción sobre el corredor de mensajería.

## 10.4 Un caso de uso: almacenamiento en caché distribuido (Redis)

Ahora tenemos dos servicios que se comunican mediante mensajería, pero en realidad no estamos haciendo nada con los
mensajes. A continuación, crearemos el ejemplo de almacenamiento en caché distribuido que analizamos anteriormente en
este capítulo. Para eso, el servicio de licencias siempre verificará en un caché de Redis distribuido los datos de la
organización asociados con una licencia en particular. Si los datos de la organización existen en el caché, devolveremos
los datos del caché. Si no es así, llamaremos al servicio de la organización y almacenaremos en caché los resultados de
la llamada en un hash de Redis.

Cuando los datos se actualizan en el servicio de la organización, el servicio de la organización enviará un mensaje a
Kafka. El servicio de licencias recogerá el mensaje y emitirá un `DELETE` contra `Redis` para `borrar el caché`.

### Almacenamiento en caché y mensajería en la nube

> El uso de Redis como caché distribuida es relevante para el desarrollo de microservicios en la nube. Puedes usar Redis
> para:
>
> Mejorar el rendimiento al buscar datos comunes. Al utilizar un caché, puede mejorar significativamente el rendimiento
> de varios servicios clave evitando lecturas en la base de datos.
>
> Reduzca la carga (y el costo) de las tablas de la base de datos que contienen sus datos. Acceder a los datos de una
> base de datos puede ser una tarea costosa. Con cada lectura, generas un evento imputable. Al utilizar un servidor
> Redis,
> puede implementar lecturas mediante una clave principal en lugar de acceder a una base de datos, lo que es
> significativamente más rentable.
>
> Aumente la resiliencia para que sus servicios puedan degradarse sin problemas si su base de datos o almacén de datos
> principal tiene problemas de rendimiento. Dependiendo de la cantidad de datos que guarde en su caché, una solución de
> almacenamiento en caché puede ayudar a reducir la cantidad de errores que puede obtener al acceder a su almacén de
> datos.
>
> **Redis es mucho más que una solución de almacenamiento en caché. Sin embargo, puede cumplir esa función si necesita
> un caché distribuido.**

## Usando Redis para almacenar en caché las búsquedas

En esta sección, comenzaremos configurando el servicio de licencias para usar `Redis`. Afortunadamente, `Spring Data`
simplifica la introducción de `Redis` en nuestro servicio de licencias. Para utilizar Redis en el servicio de
licencias, debemos hacer lo siguiente:

1. Configure el servicio de licencias para incluir las dependencias de `Spring Data Redis`.
2. Construya una `conexión` de `base de datos a Redis`.
3. Defina los repositorios de `Spring Data Redis` que nuestro código utilizará para interactuar con un hash de `Redis`.
4. Utilice `Redis` y el servicio de licencias para almacenar y leer datos de la organización.

## Configurando del servicio de licencia con dependencias de Spring Data Redis

Lo primero que debemos hacer es incluir la dependencia de `spring-boot-starter-data-redis`, en el archivo `pom.xml` del
servicio de licencias. El siguiente listado muestra esta dependencia.

````xml

<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>
</dependencies>
````

**Nota**

> En el libro se usan dos dependencias por separado: `spring-data-redis` y `jedis`, pero según el tutorial que encontré
> en la página de [baeldung: spring-data-redis-tutorial](https://www.baeldung.com/spring-data-redis-tutorial), menciona
> que de manera alternativa podemos usar el `Spring Boot starter para Redis`, lo que eliminará la necesidad de
> dependencias separadas de `spring-data` y `jedis`. Por tal razón es que yo opté por usar la dependencia de
> `spring-boot-starter-data-redis`.

## Construyendo la conexión de la base de datos a un servidor Redis

Ahora que tenemos las dependencias en Maven, necesitamos establecer una conexión con nuestro servidor Redis. Spring
utiliza el proyecto de código abierto Jedis (https://github.com/xetorthio/jedis) para comunicarse con un servidor Redis.
Para comunicarnos con una instancia específica de Redis, expondremos una clase `JedisConnectionFactory` como un
`Bean` de `Spring`.

Una vez que tengamos una conexión a `Redis`, usaremos esa conexión para crear un objeto `Spring RedisTemplate`
(en mi caso he optado por inyectar el bean `JedisConnectionFactory` por parámetro para usarlo en el otro bean
del `RedisTemplate`, mientras que en el libro no hacen esa inyeccón por parámetro, sino que usan directamente
el método `template.setConnectionFactory(jedisConnectionFactory())`).

Las clases del repositorio `Spring Data` que implementaremos en breve utilizan el objeto `RedisTemplate` para ejecutar
las consultas y guardar los datos del servicio de la organización en nuestro servicio Redis. La siguiente lista muestra
este código.

````java

@Configuration
public class RedisConfig {

    @Value("${redis.server}")
    private String redisServer;

    @Value("${redis.port}")
    private Integer redisPort;

    //Configura la conexión de la base de datos al servidor Redis
    @Bean
    public JedisConnectionFactory jedisConnectionFactory() {
        var redisStandaloneConfiguration = new RedisStandaloneConfiguration(this.redisServer, this.redisPort);
        return new JedisConnectionFactory(redisStandaloneConfiguration);
    }

    //Crea una RedisTemplate para realizar acciones para nuestro servidor Redis
    @Bean
    public RedisTemplate<String, Object> redisTemplate(JedisConnectionFactory jedisConnectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(jedisConnectionFactory);
        return template;
    }
}
````

El repositorio de Spring Cloud Config Server define las siguientes configuraciones para el servidor de Redis en el
archivo `licensing-service.yml`.

````yml
redis:
  server: localhost
  port: 6379
````

El trabajo fundamental para configurar el servicio de licencias para comunicarse con Redis está completo. Pasemos ahora
a escribir la lógica que obtendrá, agregará, actualizará y eliminará datos.

## Definiendo los repositorios de Spring Data Redis

Redis es un almacén de datos (data store) de `key-value` que actúa como un `HashMap` grande, distribuido y en memoria.
En el caso más sencillo, almacena y busca datos con una clave. No tiene ningún lenguaje de consulta sofisticado para
recuperar datos. Su simplicidad es su punto fuerte y una de las razones por las que tantos desarrolladores lo han
adoptado para utilizarlo en sus proyectos.

Debido a que usamos Spring Data para acceder a nuestro Redis store, necesitamos definir una clase de repositorio. Como
recordará desde el principio de los primeros capítulos, Spring Data utiliza clases de repositorio definidas por el
usuario para proporcionar un mecanismo simple para que una clase Java acceda a nuestra base de datos Postgres sin tener
que escribir consultas SQL de bajo nivel. Para el servicio de licencias, definiremos dos archivos para nuestro
repositorio de Redis.

`El primer archivo` es una interfaz Java que se inyectará en cualquiera de las clases de lservicios de licencia que
necesiten acceder a Redis.

````java
public interface OrganizationRedisRepository extends CrudRepository<Organization, String> {
}
````

Al extenderse desde `CrudRepository`, `OrganizationRedisRepository` contiene toda la lógica
`CRUD (Crear, Leer, Actualizar, Eliminar)` utilizada para almacenar y recuperar datos de `Redis` (en este caso).

`El segundo archivo` es el modelo que usaremos para nuestro repositorio. Esta clase es un POJO que contiene los datos
que almacenaremos en nuestra `caché de Redis`.
La clase `licensing-service/src/main/java/dev/magadiflo/licensing/app/model/Organization.java` se muestra en el
siguiente listado. Notar que en mi caso estoy usando el record que hemos venido usando desde el principio.

````java
// @RedisHash("organizations"), establece el nombre del hash en el servidor Redis 
// donde se almacenan los datos de la organización
@RedisHash("organizations")
public record Organization(@Id
                           String organizationId,
                           String name,
                           String contactName,
                           String contactEmail,
                           String contactPhone,
                           Integer port) {
}
````

Una cosa importante a tener en cuenta en el código anterior es que un servidor Redis puede contener múltiples
hashes y estructuras de datos en su interior. Por lo tanto, debemos decirle a Redis el nombre de la estructura de datos
sobre la que queremos realizar la operación en cada interacción con Redis.